---
title: "Reading Data from the Web"
output: github_document
---

```{r setup, include=FALSE}

library(tidyverse)
library(rvest)
library(httr)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuious.color = "viridis",
  ggplot2.continuious.fill = "viridis"
  
)

scale_color_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Scrape a table

I want the first table from [this page] (http://samhda.s3-us-gov-west-1.amazonaws.com/s3fs-public/field-uploads/2k15StateFiles/NSDUHsaeShortTermCHG2015.htm)

read in the html:
```{r}
url = "http://samhda.s3-us-gov-west-1.amazonaws.com/s3fs-public/field-uploads/2k15StateFiles/NSDUHsaeShortTermCHG2015.htm"
drug_use_html = read_html(url)

drug_use_html

```

extract the table(s): focus on the first one
```{r}
table_marj = 
  drug_use_html |> 
  html_table() |> 
  first() |>
  slice(-1) %>% 
  as_tibble()

table_marj
```

## Star wars movie info 

i want the data from here: https://www.imdb.com/list/ls070150896/

```{r}
swm_html = 
  read_html("https://www.imdb.com/list/ls070150896/")

```

First - need to grab the elements I want 
```{r}
title_vec = 
  swm_html |>
  html_elements(".lister-item-header a") |>
  html_text()

gross_rev_vec = 
  swm_html |>
  html_elements(".text-small:nth-child(7) span:nth-child(5)") |>
  html_text()

runtime_vec = 
  swm_html |>
  html_elements(".runtime") |>
  html_text()

swm_df = 
  tibble(
    title = title_vec,
    rev = gross_rev_vec,
    runtime = runtime_vec)
```

## Using API keys 

```{r}
nyc_water = 
  GET("https://data.cityofnewyork.us/resource/ia2d-e54m.csv") |> 
  content("parsed")
```

```{r}
nyc_water = 
  GET("https://data.cityofnewyork.us/resource/ia2d-e54m.json") |> 
  content("text") |>
  jsonlite::fromJSON() |>
  as_tibble()
```


```{r}
brfss_smart2010 = 
  GET("https://chronicdata.cdc.gov/resource/acme-vg9e.csv",
      query = list("$limit" = 5000)) |> 
  content("parsed")
```

